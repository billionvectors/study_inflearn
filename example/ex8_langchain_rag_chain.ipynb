{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07557d8-fb38-4c65-9e9c-0af5844f8209",
   "metadata": {},
   "source": [
    "## 준비하기\n",
    "1. 아래 예제를 실행하기 위해서는 사전에 ./setup.sh 파일을 실행하거나 ./start_notebook.sh 로 노트북을 구동하여 의존성 라이브러리들을 미리 설치해두셔야 합니다.\n",
    "2. qdrant서버가 떠 있어야 정상 동작합니다. ./start_qdrant.sh 를 실행하여 qdrant 서버를 띄워주세요.\n",
    "3. openapi 키가 있어야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8390b07-0291-4eac-8615-14b3d798482b",
   "metadata": {},
   "source": [
    "## 목적:\n",
    "- LangChain RAG 체인을 활용하여 벡터 기반 질의응답 시스템 구축\n",
    "\n",
    "## 왜 필요한가?\n",
    "- 벡터 기반 검색을 사용하여 LLM의 답변 정확도를 높일 수 있음\n",
    "- 기존 RAG 시스템과 LangChain을 쉽게 결합 가능\n",
    "\n",
    "## 주요 개념:\n",
    "- **RAG (Retrieval-Augmented Generation)**: 검색과 생성 모델을 결합하여 답변을 개선하는 기술\n",
    "- **LangChain**: LLM과 외부 데이터베이스(Qdrant 등)를 쉽게 연결하는 프레임워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f9c8b4-18d3-4202-8096-0bf17b91a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로딩 (아래 부분에서 오류가 발생하면 pip -r ./requirements.txt 로 의존성을 설치해주세요)\n",
    "import os\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd35864-bd15-4825-9813-b225990f63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant 연결\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "collection_name = \"sample_vectors\"\n",
    "\n",
    "# Qdrant 컬렉션 생성 (없을 경우 자동 생성)\n",
    "if not qdrant_client.collection_exists(collection_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE)  # 384는 임베딩 차원 수\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c091c54-0656-4bef-8324-ec36a4c5f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94974874-4a92-41a3-9105-c288e47c4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant 기반 벡터 저장소 생성\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914ab105-649d-4e59-9f81-cd739dacc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API 키 설정 (환경 변수에서 가져오거나 기본값 설정)\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"your_api_key\")\n",
    "\n",
    "# LLM 설정 (GPT API)\n",
    "llm = ChatOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3220ec2-151d-4a2f-a073-979fb376b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 프롬프트 설정\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5deb9e-8a21-4412-8379-89b94d2ce55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 결합 체인 생성\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# RAG 체인 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1af4ee5-bf59-4783-ae37-f7612c654fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 응답: Vector databases are used to store and analyze geographical data, as they are optimized for spatial data and operations. They allow for efficient querying, storage, and retrieval of complex spatial information such as points, lines, and polygons. Vector databases enable applications like geographic information systems (GIS) to handle and process spatial data effectively.\n"
     ]
    }
   ],
   "source": [
    "# 질문 실행 및 응답 출력\n",
    "question = \"What is the purpose of vector databases?\"\n",
    "response = qa_chain.invoke({\"input\": question})\n",
    "print(\"LLM 응답:\", response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
