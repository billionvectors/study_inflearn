{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70274460-50a9-4547-af3b-8719c1891108",
   "metadata": {},
   "source": [
    "## 준비하기\n",
    "1. 아래 예제를 실행하기 위해서는 사전에 ./setup.sh 파일을 실행하거나 ./start_notebook.sh 로 노트북을 구동하여 의존성 라이브러리들을 미리 설치해두셔야 합니다.\n",
    "2. qdrant서버가 떠 있어야 정상 동작합니다. ./start_qdrant.sh 를 실행하여 qdrant 서버를 띄워주세요.\n",
    "3. openapi 키가 있어야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13fa10-2406-41c1-9748-1a3695fd59b0",
   "metadata": {},
   "source": [
    "## 목적:\n",
    "- Qdrant를 활용하여 Retrieval-Augmented Generation(RAG) 실습\n",
    "- 벡터 검색을 통해 GPT 모델의 응답을 향상시킴\n",
    "\n",
    "## 왜 필요한가?\n",
    "- 단순한 질의응답 시스템보다 정확한 정보를 제공할 수 있음\n",
    "- AI 챗봇이나 검색 시스템을 개선하는 데 활용 가능\n",
    "\n",
    "## 주요 개념:\n",
    "- **RAG (Retrieval-Augmented Generation)**: 검색과 생성 모델을 결합하여 더 정확한 응답을 제공하는 기술\n",
    "- **Qdrant**: 대규모 벡터 데이터를 검색하는 데 최적화된 벡터 데이터베이스\n",
    "- **LLM (Large Language Model)**: 대규모 자연어 처리 모델, 예: GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2668a27-cb8b-4f44-a478-a456907c04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로딩 (아래 부분에서 오류가 발생하면 pip -r ./requirements.txt 로 의존성을 설치해주세요)\n",
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f7b16f-2cae-47ce-be2c-a8578bbd6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant 연결\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "collection_name = \"ex5_sample_vectors\"\n",
    "\n",
    "# Qdrant 컬렉션 생성 (없을 경우 자동 생성)\n",
    "if not qdrant_client.collection_exists(collection_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE)  # 384는 임베딩 차원 수\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c7b5c3-88a4-4977-8555-33ed09f22e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8654d970-0beb-4915-b627-ac2c846a1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant 기반 벡터 저장소 생성\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2616eaf8-9d80-4fcb-aecb-4136fef10afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API 키 설정 (환경 변수에서 가져오거나 기본값 설정)\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"your_api_key\")\n",
    "\n",
    "# LLM 모델 (GPT API) 설정\n",
    "llm = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8434ff2-4894-414e-b5a3-f2b79bfcfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9328d85-4719-4e17-956d-21d35681f069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 응답: {'query': '오늘의 날씨를 알려줘', 'result': \"\\nI'm sorry, I do not have information on the weather for today.\"}\n"
     ]
    }
   ],
   "source": [
    "# 질문 실행\n",
    "question = \"오늘의 날씨를 알려줘\"\n",
    "response = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "# 응답 출력\n",
    "print(\"LLM 응답:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cfbc7-6735-4cf6-90aa-d6db777cd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: 데이터 넣고 결과가 변경된것을 보여야함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
